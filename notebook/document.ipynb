{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9958fae3",
   "metadata": {},
   "source": [
    "## data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a4035",
   "metadata": {},
   "source": [
    "### step1: loading pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe0b36b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.document_loaders'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# directory loader\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DirectoryLoader\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# text loader\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.document_loaders'"
     ]
    }
   ],
   "source": [
    "# directory loader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "# text loader\n",
    "from langchain.document_loaders import TextLoader\n",
    "#pdf loader\n",
    "from langchain.document_loaders import PyPDFLoader, PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_loader=DirectoryLoader(\n",
    "    path=\"../data/pdfs\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls= PyMuPDFLoader,\n",
    "    show_progress=True\n",
    ")\n",
    "pdfDocuments= dir_loader.load()\n",
    "pdfDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pdfDocuments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f771921a",
   "metadata": {},
   "source": [
    "#### So, the pdfDocuments is a list of Documents (metadata + page_content) and each document contains a page of the pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6c298",
   "metadata": {},
   "source": [
    "### respliting documents into chunks to reduce the number of tokens given to the embedding model and to make the embedding process more specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def split_documents(documents: List[Document], chunk_size: int=1000, chunk_overlap: int=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs=text_splitter.split_documents(documents)\n",
    "    print(f\"{len(documents)} splitted into {len(split_docs)} chunks\")\n",
    "    if split_docs:\n",
    "        print(\"exemple chunk:\")\n",
    "        print(f\"content:{split_docs[1].page_content[:200]}\")\n",
    "        print(f\"metadata: {split_docs[1].metadata}\")\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b29bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks=split_documents(pdfDocuments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c563fef5",
   "metadata": {},
   "source": [
    "### step2: embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea352ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1844ba0c",
   "metadata": {},
   "source": [
    "### creating the Embedding manager class that:\n",
    "* loads the embedding model \n",
    "* contains a methode for generating the embedding (it takes a list of texts -> returns a numpy array of correspending embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "    #embedding using SentenceTransformer\n",
    "    def __init__(self, model_name: str=\"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"Attributes:\n",
    "            model_name:model name\n",
    "            model: initialized automaticaly using the private methode _load_model\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            print(f\"loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error in loading the embedding model: {self.model_name}: {e}\")\n",
    "            raise\n",
    "    def generate_embedding(self, texts:list[str])->np.ndarray:\n",
    "        if not(self.model):\n",
    "            raise ValueError(\"model not loaded\")\n",
    "        print(f\"generate embeddings for {len(texts)} texts:\")\n",
    "        embeddings=self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"embeddings shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1043f28d",
   "metadata": {},
   "source": [
    "### initialize the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dfb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_manager = EmbeddingManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f19a9",
   "metadata": {},
   "source": [
    "### step3: vector store with chromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a8e45",
   "metadata": {},
   "source": [
    "prerequisites: every document loaded is composed of : **metadata** and **page content** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f97f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfDocuments[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfDocuments[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class VectorStore:\n",
    "    def __init__(self, collection_name: str=\"pdf_documents\", persist_directory=\"../data/vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory= persist_directory\n",
    "        self.client = None \n",
    "        self.collection=None\n",
    "        self._initialize_store()\n",
    "    def _initialize_store(self):\n",
    "        try:\n",
    "            #chromadb client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # chromadb collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata= {\"description\" : \"pdf documents embedded for RAG\"}\n",
    "            )\n",
    "            print(f\"vector store initialized . collection: {self.collection_name}\")\n",
    "            print(f\"number of documents in the collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error initializing vectore store:{e}\")\n",
    "            raise\n",
    "\n",
    "    # function to add new documents:\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        if len(documents)!=len(embeddings):\n",
    "            raise ValueError(\"number of documents must match the number of embeddings\")\n",
    "        print(f\"adding{len(documents)} to the collection (vectore store)\")\n",
    "        #preparing data to chromadb:\n",
    "        ids=[]\n",
    "        metadatas=[]\n",
    "        documents_text=[]\n",
    "        embedding_list=[]\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # step1: generate a unique ID:\n",
    "            doc_id=f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            # step2-1: prepare metadata:\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index']= i\n",
    "            metadata['content_length']=len(doc.page_content)\n",
    "            #step2-2:apend the metadata to the metadatas list\n",
    "            metadatas.append(metadata)\n",
    "            #step3: apend the page content of the doc to the documents_text\n",
    "            documents_text.append(doc.page_content)\n",
    "            #step4: apend the embedding of current doc to the embeddings list\n",
    "            embedding_list.append(embedding.tolist())\n",
    "\n",
    "        #add to collection:\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids= ids, \n",
    "                embeddings= embedding_list,\n",
    "                metadatas= metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"{len(ids)} documents were added to the vector  store\")\n",
    "            print(f\"tatale documents in the collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error in adding new documents to the collection: {e}\")\n",
    "            raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116bf173",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorestore=VectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91747b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b067207",
   "metadata": {},
   "source": [
    "### convert text to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts= [doc.page_content for doc in chunks]\n",
    "# generate the embeddings:\n",
    "embeddings= embedding_manager.generate_embedding(texts)\n",
    "\n",
    "#store texts and embeddings into vector\n",
    "vectorestore.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29549511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Prepared {len(texts)} texts for embedding\")\n",
    "print(f\"First text sample: {texts[0][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ff1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc38cba",
   "metadata": {},
   "source": [
    "## 2- data retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    def __init__(self, vectore_store: VectorStore, embedding_manager:EmbeddingManager):\n",
    "        self.vectore_store = vectore_store\n",
    "        self.embedding_manager=embedding_manager\n",
    "    def retrieve(self, query: str, top_k:int=5, score_threshold: float= -0.1)->List[Dict[str, Any]]:\n",
    "        \"\"\"args:\n",
    "                query=question+context\n",
    "                top_k: umber of top results to return\n",
    "                score_threshold: min score of similarity (threshold)\"\"\"\n",
    "        #generate query embedding:\n",
    "        print(\"1\")\n",
    "        query_embedding=self.embedding_manager.generate_embedding([query])[0]\n",
    "        try:\n",
    "            print(\"2\")\n",
    "            results= self.vectore_store.collection.query(query_embeddings=[query_embedding.tolist()],\n",
    "                                                         n_results=top_k)\n",
    "            retrieved_docs=[]\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents=results['documents'][0]\n",
    "                print(documents[0])\n",
    "                metadatas=results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids=results['ids'][0]\n",
    "                for i, (doc_id, doc_distance, doc_metadata, doc_content) in enumerate(zip(ids, distances, metadatas, documents)):\n",
    "                    similarity_score= 1 - doc_distance\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id':doc_id,\n",
    "                            'content': doc_content,\n",
    "                            'metadata': doc_metadata,\n",
    "                            'distance': doc_distance,\n",
    "                            'rank': i+1\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"the: document: {doc_content} is not admitted beecause it has the similarity score under 0: {similarity_score}\")\n",
    "                print(f\"retrieved: {len(retrieved_docs)} documents after filtering\")\n",
    "                # Vérifiez comment vous comptez les documents\n",
    "                print(f\"Nombre réel de documents récupérés: {len(retrieved_docs)}\")\n",
    "            else:\n",
    "                print(\"no documents found\")\n",
    "                print\n",
    "            return retrieved_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error in embedding the query: {e}\") \n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    def __init__(self, vectore_store: VectorStore, embedding_manager:EmbeddingManager):\n",
    "        self.vectore_store = vectore_store\n",
    "        self.embedding_manager=embedding_manager\n",
    "    def retrieve(self, query: str, top_k:int=5, score_threshold: float= 0.5)->List[Dict[str, Any]]:\n",
    "        \"\"\"args:\n",
    "                query=question+context\n",
    "                top_k: umber of top results to return\n",
    "                score_threshold: min score of similarity (threshold)\"\"\"\n",
    "        #generate query embedding:\n",
    "        print(\"1\")\n",
    "        query_embedding=self.embedding_manager.generate_embedding([query])[0]\n",
    "        try:\n",
    "            print(\"2\")\n",
    "            results= self.vectore_store.collection.query(query_embeddings=[query_embedding.tolist()],\n",
    "                                                         n_results=top_k)\n",
    "            \n",
    "            return results['documents'][0]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error in embedding the query: {e}\") \n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa3a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever=RAGRetriever(vectorestore, embedding_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e86f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever.retrieve(\"quelle est la definition de la big data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b4694",
   "metadata": {},
   "source": [
    "## finale step: test:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c61ff",
   "metadata": {},
   "source": [
    "## 1-test1: question sur le premier document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever.retrieve(\"qu'elle sont les different types des données\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430efc4f",
   "metadata": {},
   "source": [
    "## 3-test2: question sur le deuxieme document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15346f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever.retrieve(\"donne moi les differents concepts de kafka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d393c0",
   "metadata": {},
   "source": [
    "## 3-test3: question sur le 3eme document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever.retrieve(\"donne moi une idée sur l'entreprise yazaki\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cffebc6",
   "metadata": {},
   "source": [
    "## query retrievel pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3aee94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
